---
title: "HW2 (25.10.2018)"
author: "Dilara Aykanat - IE582 - Fall 2018"
output: html_document
---

All codes are given in the appendix under the corresponding part of the related questions with their explanations.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_chunk$set(out.width='\\textwidth')

require(data.table)
require(MASS)
require(jpeg)

```

##Task 1-2
###Part-a-b-c
In this part, we take home odd for bookmaker x, away odd for bookmaker x, tie odd for bookmaker x, over 2.5 odd for bookmaker x, under 2.5 odd for bookmaker x, both teams to score/YES for bookmaker x, over 0.5 odd for bookmaker x, under 0.5 odd for bookmaker x for 5 different bookmakers ('Tipico','ComeOn','Betsafe','Unibet','SBOBET') separately, and apply PCA. Note that not all the bookmakers have given odds for every type of these bets. Final odds are taken into consideration. 

Let us start with bookmaker Unibet. We see that the first two components capture 95% of the total variance. We also notice that away win odd and under 0.5 odd are found to be the features that capture the variability within all features the most (the absolute value of the eigenvalues of the first component are largest for these two bet types). 

```{r u,echo=FALSE,fig.width = 10.5,fig.height=10}
pca=readRDS("C:/Users/diaykanat/Documents/pca_u.rds")
summary(pca)
pca$loadings
```

This is the summary of the PCA for bookmaker Tipico. The first two components capture 99% of the total variance which is quite good. Away win odd again has the absolute largest eigenvalue. Note that Tipico did not give any odd for over/under 0.5.

```{r t,echo=FALSE,fig.width = 10.5,fig.height=10}
pca=readRDS("C:/Users/diaykanat/Documents/pca_t.rds")
summary(pca)
pca$loadings
```

This is the summary of the PCA for bookmaker ComeOn. This time, the PC1 is not as succesful as in the previous two bookmakers' analysis at capturing the variance (69%).  Away win odd is again the most significant one. 

```{r comeon,echo=FALSE,fig.width = 10.5,fig.height=10}
pca=readRDS("C:/Users/diaykanat/Documents/pca_c.rds")
summary(pca)
pca$loadings
```

These are the summary of the PCA for bookmaker Betsafe.Note that Betsafe have given odds for every bet type. Under 0.5 odd and away win are the most significant ones. We can say that as the number of the features increases, the cumulative proportion of the first two components decreases as expected. PC1 captures 65% of the variability and PC2 captures 29%.

```{r betsafe,echo=FALSE,fig.width = 10.5,fig.height=10}
pca=readRDS("C:/Users/diaykanat/Documents/pca_b.rds")
summary(pca)
pca$loadings
```

These are the summary of the PCA for bookmaker SBOBET. The PC1 has captured a great amount of the total variance (%82). Away win odds are found to be the most significant for Comp1 as its loading has the largest absolute value 0.88. There was no 0.5 under/over and BTS odd given by this bookmaker.

```{r SBOBET,echo=FALSE,fig.width = 10.5,fig.height=10}
pca=readRDS("C:/Users/diaykanat/Documents/pca_s.rds")
summary(pca)
pca$loadings
```

Remarks for this part are:

1.  Tipico and SBOBET's PCA mappings could make a relatively better distinction between different types of match outcomes (home,tie,away). They have a sharper v-shaped mapping. We could say that their odds are useful in clustering. One of the reason for that is that their feature set is smaller compared to others.

2.   We remark that the match outcome of under/over 2.5 could not be captured well in all 5 bookmakers odds' PCA anaysis as the scores' plot has no distinction between red and black dots. Same remark holds for MDS,  neither in Euclidian distances nor in Manhattan distances, the black and red dots show no pattern in 2D Representations. They can maybe be distinguished in 3d respresentations or maybe extra features (extra bet types) should be included in our set. 

3.  Home/Away results are clearly distinguished in the plots given below on the RHS. We can say that this feature set may be successful to give insight about Home/Away results in contrast to the over/under 2.5 results. Black and red dots are separated on the PCA mappings over PC1 and PC2 (for home/away case not over under case). Another remark is that the green dots (tie results) could not be distinguished very well. So it can be said that it is hard for all 5 bookmakers to predict a tie result rather than an away win or a home win.   

4.  V-Shape of the scores is quite common in real data. Two types of information (home and away) are distinguished in two edges and the meeting point forms the tie results.

5.  For especially Tipico and SBOBET, Euclidian distance MDS Representations are much more sharper V-shaped compared to the Manhattan distances which indicates that Eucld.dist. is better for MDS in this dataset, the variance of the data could be decreased significantly. In other bookmakers, there seem to be no difference. 

6.  Except from Tipico and SBOBET where MDS and PCA both perform well, MDS does not overperform PCA. Note that MDS is strong when there are few dimensions which 
supports our interpretation of the plots because the dimension is higher in other bookmakers. Remember that there is a phenomenon called "curse of dimensionality" which says that if the number of the features gets high, the ability to interpret the inter-distances decreases.

7.  There is a layer-like mapping in the plots which is the clearest in Unibet. 


```{r aa,echo=FALSE,fig.width = 10.5,fig.height=55}

emds=readRDS("C:/Users/diaykanat/Documents/emds_u.rds")
mmds=readRDS("C:/Users/diaykanat/Documents/mmds_u.rds")
pca=readRDS("C:/Users/diaykanat/Documents/pca_u.rds")
results=readRDS("C:/Users/diaykanat/Documents/results_u.rds")
results2=readRDS("C:/Users/diaykanat/Documents/results2_u.rds")

par(mfrow = c(10,2))
plot(pca$scores[,1],pca$scores[,2],main='2D Scores of PCA\n for Unibet',cex.main = 1,col=results+1,pch=".",cex=7,xlab="Comp1 Mapped Score",ylab="Comp2 Mapped Score") 
legend("topleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 5,pt.cex = 7)
plot(pca$scores[,1],pca$scores[,2],,main='2D Scores of PCA\n for Unibet',cex.main = 1,col=results2+1,pch=".",cex=7,xlab="Comp1 Mapped Score",ylab="Comp2 Mapped Score") 
legend("topleft", legend=c("Home","Away","Tie"),col=c(1,2,3), pch = ".",cex=1,text.width = 5,pt.cex = 7)

plot(emds[,1],emds[,2],main='2D Representation of MDS Results using Euclidean Distances\n for Unibet',cex.main = 1,xlab='', ylab='',col=results+1,pch=".",cex=7)
legend("bottomleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 5,pt.cex = 7)

plot(mmds[,1],mmds[,2],main='2D Representation of MDS Results using Manhattan Distances\n for Unibet',xlab='',cex.main = 1, ylab='',col=results+1,pch=".",cex=7)
legend("bottomleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 10,pt.cex = 7)

emds=readRDS("C:/Users/diaykanat/Documents/emds_t.rds")
mmds=readRDS("C:/Users/diaykanat/Documents/mmds_t.rds")
pca=readRDS("C:/Users/diaykanat/Documents/pca_t.rds")
results=readRDS("C:/Users/diaykanat/Documents/results_t.rds")
results2=readRDS("C:/Users/diaykanat/Documents/results2_t.rds")

plot(pca$scores[,1],pca$scores[,2],main='2D Scores of PCA\n for Tipico',cex.main = 1,col=results+1,pch=".",cex=7,xlab="Comp1 Mapped Score",ylab="Comp2 Mapped Score") 
legend("topleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 5,pt.cex = 7)
plot(pca$scores[,1],pca$scores[,2],,main='2D Scores of PCA\n for Tipico',cex.main = 1,col=results2+1,pch=".",cex=7,xlab="Comp1 Mapped Score",ylab="Comp2 Mapped Score") 
legend("topleft", legend=c("Home","Away","Tie"),col=c(1,2,3), pch = ".",cex=1,text.width = 5,pt.cex = 7)

plot(emds[,1],emds[,2],main='2D Representation of MDS Results using Euclidean Distances\n for Tipico',cex.main = 1,xlab='', ylab='',col=results+1,pch=".",cex=7)
legend("bottomleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 5,pt.cex = 7)

plot(mmds[,1],mmds[,2],main='2D Representation of MDS Results using Manhattan Distances\n for Tipico',xlab='',cex.main = 1, ylab='',col=results+1,pch=".",cex=7)
legend("bottomleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 10,pt.cex = 7)

emds=readRDS("C:/Users/diaykanat/Documents/emds_c.rds")
mmds=readRDS("C:/Users/diaykanat/Documents/mmds_c.rds")
pca=readRDS("C:/Users/diaykanat/Documents/pca_c.rds")
results=readRDS("C:/Users/diaykanat/Documents/results_c.rds")
results2=readRDS("C:/Users/diaykanat/Documents/results2_c.rds")

plot(pca$scores[,1],pca$scores[,2],main='2D Scores of PCA\n for ComeOn',cex.main = 1,col=results+1,pch=".",cex=7,xlab="Comp1 Mapped Score",ylab="Comp2 Mapped Score") 
legend("topleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 5,pt.cex = 7)
plot(pca$scores[,1],pca$scores[,2],,main='2D Scores of PCA\n for ComeOn',cex.main = 1,col=results2+1,pch=".",cex=7,xlab="Comp1 Mapped Score",ylab="Comp2 Mapped Score") 
legend("topleft", legend=c("Home","Away","Tie"),col=c(1,2,3), pch = ".",cex=1,text.width = 5,pt.cex = 7)

plot(emds[,1],emds[,2],main='2D Representation of MDS Results using Euclidean Distances\n for ComeOn',cex.main = 1,xlab='', ylab='',col=results+1,pch=".",cex=7)
legend("bottomleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 5,pt.cex = 7)

plot(mmds[,1],mmds[,2],main='2D Representation of MDS Results using Manhattan Distances\n for ComeOn',xlab='',cex.main = 1, ylab='',col=results+1,pch=".",cex=7)
legend("bottomleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 10,pt.cex = 7)

emds=readRDS("C:/Users/diaykanat/Documents/emds_b.rds")
mmds=readRDS("C:/Users/diaykanat/Documents/mmds_b.rds")
pca=readRDS("C:/Users/diaykanat/Documents/pca_b.rds")
results=readRDS("C:/Users/diaykanat/Documents/results_b.rds")
results2=readRDS("C:/Users/diaykanat/Documents/results2_b.rds")

plot(pca$scores[,1],pca$scores[,2],main='2D Scores of PCA\n for Betsafe',cex.main = 1,col=results+1,pch=".",cex=7,xlab="Comp1 Mapped Score",ylab="Comp2 Mapped Score") 
legend("topleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 5,pt.cex = 7)
plot(pca$scores[,1],pca$scores[,2],,main='2D Scores of PCA\n for Betsafe',cex.main = 1,col=results2+1,pch=".",cex=7,xlab="Comp1 Mapped Score",ylab="Comp2 Mapped Score") 
legend("topleft", legend=c("Home","Away","Tie"),col=c(1,2,3), pch = ".",cex=1,text.width = 5,pt.cex = 7)

plot(emds[,1],emds[,2],main='2D Representation of MDS Results using Euclidean Distances\n for Betsafe',cex.main = 1,xlab='', ylab='',col=results+1,pch=".",cex=7)
legend("bottomleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 5,pt.cex = 7)

plot(mmds[,1],mmds[,2],main='2D Representation of MDS Results using Manhattan Distances\n for Betsafe',xlab='',cex.main = 1, ylab='',col=results+1,pch=".",cex=7)
legend("bottomleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 10,pt.cex = 7)

emds=readRDS("C:/Users/diaykanat/Documents/emds_s.rds")
mmds=readRDS("C:/Users/diaykanat/Documents/mmds_s.rds")
pca=readRDS("C:/Users/diaykanat/Documents/pca_s.rds")
results=readRDS("C:/Users/diaykanat/Documents/results_s.rds")
results2=readRDS("C:/Users/diaykanat/Documents/results2_s.rds")

plot(pca$scores[,1],pca$scores[,2],main='2D Scores of PCA\n for SBOBET',cex.main = 1,col=results+1,pch=".",cex=7,xlab="Comp1 Mapped Score",ylab="Comp2 Mapped Score") 
legend("topleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 5,pt.cex = 7)
plot(pca$scores[,1],pca$scores[,2],,main='2D Scores of PCA\n for SBOBET',cex.main = 1,col=results2+1,pch=".",cex=7,xlab="Comp1 Mapped Score",ylab="Comp2 Mapped Score") 
legend("topleft", legend=c("Home","Away","Tie"),col=c(1,2,3), pch = ".",cex=1,text.width = 5,pt.cex = 7)

plot(emds[,1],emds[,2],main='2D Representation of MDS Results using Euclidean Distances\n for SBOBET',cex.main = 1,xlab='', ylab='',col=results+1,pch=".",cex=7)
legend("bottomleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 5,pt.cex = 7)

plot(mmds[,1],mmds[,2],main='2D Representation of MDS Results using Manhattan Distances\n for SBOBET',xlab='',cex.main = 1, ylab='',col=results+1,pch=".",cex=7)
legend("bottomleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 10,pt.cex = 7)

```

## Task 3
###Part 2a-b

The image below shows a picture of me taken on a street. We first read the image as a variable.
The variable is a 512X512X3 matrix. It is actually an ensemble of 3 separate 512X512 matrices, each matrix corresponding to a channel (R,G and B). Each value of the matrix shows the intensity of the pixel of the related channel. 


```{r a0,echo=FALSE,fig.width = 5,fig.height=5,fig.align='center'}

resim <- readJPEG("HW2_Resim.jpg")

par(mar=c(1,0,0,0))
plot(0:1,0:1,axes=FALSE,type="n",ann = FALSE)
title(xlab="Original Picture", line=0, cex.lab=1.2)
rasterImage(resim,0,0,1,1)
#dim(resim)
```

Now let's display each channel separately. We reverse and transpose the matrices to obtain a proper display (not reversed because of the image() function). The original picture is actually obtained by 'superposing' these three channels' intensities.


```{r a1,echo=FALSE,fig.width = 21,fig.height= 7}
par(mfrow=c(1,3))
resimr1 <- apply(resim[,,1], 2, rev)
resimr2 <- apply(resim[,,2], 2, rev)
resimr3 <- apply(resim[,,3], 2, rev)

image(t(resimr1),xlab = 'Channel 1 (Red)',cex.lab = 3, axes=FALSE,col = rgb(seq(0, 1, length = 256),0,0))
image(t(resimr2),xlab = 'Channel 2 (Green)',cex.lab = 3,axes=FALSE,col = rgb(0,seq(0, 1, length = 256),0))
image(t(resimr3),xlab = 'Channel 3 (Blue)',cex.lab = 3,axes=FALSE,col = rgb(0,0,seq(0, 1, length = 256)))



```

###Part 3a-b
In this part, we add a uniform random noise [0,1] to each pixel value for each channel of original image. Note that we scale the resulting pixel values so that the range stays between 0 and 1 to be able to display the image.


```{r a2,echo=FALSE,fig.width = 5,fig.height=5,fig.align='center'}
m<-resim
par(mar=c(1,0,0,0))

#add noise to every channel
m[,,1]<-resim[,,1] + matrix(runif(512*512,0,0.1),512,512)
m[,,2]<-resim[,,2] + matrix(runif(512*512,0,0.1),512,512)
m[,,3]<-resim[,,3] + matrix(runif(512*512,0,0.1),512,512)
#normalize the values
m<-m/max(m)
#display the image with added noise
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
title(xlab="Original Picture + Uniform Noise", line=0, cex.lab=1.2)
rasterImage(m,0,0,1,1)
```

Now let's display each channel separately using “image” function on a single plot.

```{r a3,echo=FALSE,fig.width = 21,fig.height= 7}
par(mfrow=c(1,3))
mr1 <- apply(m[,,1], 2, rev)
mr2 <- apply(m[,,2], 2, rev)
mr3 <- apply(m[,,3], 2, rev)

image(t(mr1),xlab = 'Channel 1 (Red) + Noise',cex.lab = 3,axes=FALSE,col = rgb(seq(0, 1, length = 256),0,0)) 
image(t(mr2),xlab = 'Channel 2 (Green) + Noise',cex.lab = 3,axes=FALSE,col = rgb(0,seq(0, 1, length = 256),0))
image(t(mr3),xlab = 'Channel 3 (Blue) + Noise',cex.lab = 3,axes=FALSE,col = rgb(0,0,seq(0, 1, length = 256)))
```

###Part 4a
In this part, we first transform the noisy image to greyscale by just summing & scaling R,G,B pixel values.

```{r a4,echo=FALSE,fig.width = 5,fig.height=5,fig.align='center'}
#take the summation of the three channels to convert to grayscale
par(mar=c(1,0,0,0))
g<-m[,,1]+m[,,2]+m[,,3]
#scale the values
g<-g/max(g)
plot(0:1,0:1,type="n",axes=FALSE,ann=FALSE)
title(xlab="Greyscale Noisy Image", line=0, cex.lab=1.2)
rasterImage(g,0,0,1,1)
```


We than extract patches of size 9X9 resulting in a total number of 260100 patches for this 512X512 pixel picture. Each patch corresponds to a row and each pixel index (top-left pixel of a patch for example) corresponds to a column in the resulting dataframe (matrix in my code). We apply pca to this matrix.

```{r a5,echo=FALSE,fig.width = 13}
#extract the patches and build the dataframe
count = 0
liste <-list(NULL)
for(i in c(1:510)){for(j in c(1:510)){
  vect<-c(((t(g[c(i:(i+2)),c(j:(j+2))]))))
  count = count + 1
  liste[[count]] = vect
}}

liste <-t(as.data.table(liste[]))
#reset the row indexes
rownames(liste) <-NULL
pca<-princomp(liste)
summary(pca)
pca$loadings
```

We can see from the summary of PCA results that the first component catched %97 of the total variance which is quite good.  
The eigenvectors of the first component have nearly the same values which means that each pixel intensity value in a patch has equal weight(importance) on the mappings. With this property, we could reconstruct the picture with a minimal loss in the following part. 

###Part 4b

As expected, the first component was able to catch the most variance. The mappings on the first component form just a slightly blurred version of the original picture whereas the mappings on the second and the third are only capable of showing borderlines. However if our aim is to catch the borders/edges, PC2 and PC3 scores can be very beneficial. 
We know that the components are orthogonal to each other by definition of PCA. The second and third component give a 'relief-like' mapping in which the scores are of opposite sign. We can see this in the contrast between the second and the third picture below: the black areas (right side of the arm for example) in the second are shown as white in the third picture.

Note that we again scaled the mappings to [0,1] in order to be able to plot the images.

```{r partb, echo=FALSE,fig.width=21,fig.height = 7}

#component1
z<-pca$scores[,1]
z<-((z-min(z))/(max(z)-min(z)))
z<-t(matrix(z,510,510))
z <- apply(z, 2, rev)

#component2
y<-pca$scores[,2]
y<-((y-min(y))/(max(y)-min(y)))
y<-t(matrix(y,510,510))
y <- apply(y, 2, rev)

#component3
x<-pca$scores[,3]
x<-((x-min(x))/(max(x)-min(x)))
x<-t(matrix(x,510,510))
x <- apply(x, 2, rev)

par(mfrow=c(1,3))
image(t(z),xlab = 'Comp1 Scores',cex.lab = 3,axes=FALSE,col = grey(seq(0, 1, length = 256))) 
image(t(y),xlab = 'Comp2 Scores',cex.lab = 3,axes=FALSE,col = grey(seq(0, 1, length = 256)))
image(t(x),xlab = 'Comp3 Scores',cex.lab = 3,axes=FALSE,col = grey(seq(0, 1, length = 256)))



```

###Part 4c

Each eigenvector of a component actually shows the 'importance' given to a specific pixel in a patch.
First component's eigenvector's image is nearly a symmetric one. Actually, it should be shown as the same color for all 9 pixels it is shown as a separate plot below, -note that 'rasterImage' function gives a fully gray image whereas 'image' function scales the matrix and changes the intensities- because the eigenvectors have equal values but because of the scaling, the intensity values are changed. There is an equal weighting of the pixels of a patch in PC1. 

We see that in PC2, topleft(white) and bottom right(black) pixels are valued the most. In PC3 topright and bottomleft are the emphasized ones. One can again remark this in the second and third pictures above: Comp2 Image's lines are sharper in the upleft-bottomright direction whereas the opposite is true for Comp3(top of the right shoulder & the diagonal window of the white car behind could be catched in Comp3 Image above).

```{r taskk2, echo=FALSE,fig.width=3,fig.height=3,fig.align="center"}
l1<-matrix(pca$loadings[,1],3,3)
#l1 <- apply(l1, 2, rev)
#image((l1),xlab = 'Eigenvectors (without scaling) for Comp1',cex.lab = 3,axes=FALSE,col = grey(seq(0, 1, length #= 256)))

par(mar=c(1,0,0,0))
plot(0:1,0:1,type="n",axes=FALSE,ann=FALSE)
title(xlab='Eigenvectors (without scaling) for Comp1', line=0, cex.lab=0.8)
rasterImage(l1,0,0,1,1)
```

```{r task2, echo=FALSE,fig.width=21,fig.height=7}
par(mfrow=c(1,3))
l1<-matrix(pca$loadings[,1],3,3)
l1 <- apply(l1, 2, rev)
l1<-((l1-min(l1))/(max(l1)-min(l1)))
image(t(l1),xlab = 'Eigenvectors for Comp1',cex.lab = 3,axes=FALSE,col = grey(seq(0, 1, length = 256)))

l2<-matrix(pca$loadings[,2],3,3)
l2 <- apply(l2, 2, rev)
l2<-((l2-min(l2))/(max(l2)-min(l2)))
image(t(l2),xlab = 'Eigenvectors for Comp2',cex.lab = 3,axes=FALSE,col = grey(seq(0, 1, length = 256)))

l3<-matrix(pca$loadings[,3],3,3)
l3 <- apply(l3, 2, rev)
l3<-((l3-min(l3))/(max(l3)-min(l3)))
image(t(l3),xlab = 'Eigenvectors for Comp3',cex.lab = 3,axes=FALSE,col = grey(seq(0, 1, length = 256)))
```

##Appendix

###Task1-2

```{r appendix_prep, eval=FALSE}
require(data.table)
require(MASS)
require(jpeg)
matches_file_path="C:/Users/diaykanat/Desktop/IE 582/HW1/matches.rds"
odd_details_file_path="C:/Users/diaykanat/Desktop/IE 582/HW1/odd_details.rds"

#read the data
matches=readRDS(matches_file_path)
odds=readRDS(odd_details_file_path)

#prepare the total scores and over/under
matches=unique(matches)
matches[,c("HomeGoals","AwayGoals"):=tstrsplit(score,':')]
matches[,Year:=year(match_time)]
matches$HomeGoals=as.numeric(matches$HomeGoals)
matches[,AwayGoals:=as.numeric(AwayGoals)]
matches[,TotalGoals:=HomeGoals+AwayGoals]
matches[,IsOver:=0]
matches[TotalGoals>2.5,IsOver:=1]
matches[HomeGoals>AwayGoals,Result:=0]  #HOME
matches[HomeGoals<AwayGoals,Result:=1]  #AWAY
matches[HomeGoals==AwayGoals,Result:=2]  #TIE
matches=matches[complete.cases(matches)]

#take the final odds
odds_f=odds[,list(final_odd=odd[.N]),by=list(matchId,oddtype,bookmaker,totalhandicap)]

#try this for 5 bookmakers separately
odds_f=odds_f[bookmaker %in% c('Unibet') #'Tipico','ComeOn','Betsafe','Unibet','SBOBET'
             & (is.na(totalhandicap) | totalhandicap == 2.5 | totalhandicap == 0.5)
             & (oddtype %in% c("odd1","odd2","oddX","YES","NO","over","under"))]

#merge with the real match results
odds_f_wide=dcast(odds_f,matchId~oddtype + bookmaker + totalhandicap,value.var='final_odd')
odds_f_wide=odds_f_wide[complete.cases(odds_f_wide)]
merged_matches=merge(matches,odds_f_wide,by='matchId')

#take the result vectors
results<-merged_matches$IsOver
results2<-merged_matches$Result
merged_matches<-merged_matches[,-c(1:12)]

#apply PCA and display the results
pca=princomp(merged_matches)
str(pca)
summary(pca)
plot(pca$scores[,1],pca$scores[,2],col=results+1,pch=".",cex=7) 
plot(pca$scores[,1],pca$scores[,2],col=results2+1,pch=".",cex=7) 

#compute the distance matrices 
e = dist(merged_matches, method = "euclidean")
m = dist(merged_matches, method = "manhattan")

#apply mds
emds=cmdscale(e)
mmds=cmdscale(m)

#plot the scores and show in different colors according to the result vectors separetely for over/under 2.5 and home/tie/away cases
#put the legends separately for each bookmaker
#20 plots in total
par(mfrow = c(10,2))
plot(pca$scores[,1],pca$scores[,2],main='2D Scores of PCA\n for Unibet',cex.main = 1,col=results+1,pch=".",cex=7,xlab="Comp1 Mapped Score",ylab="Comp2 Mapped Score") 
legend("topleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 5,pt.cex = 7)
plot(pca$scores[,1],pca$scores[,2],,main='2D Scores of PCA\n for Unibet',cex.main = 1,col=results2+1,pch=".",cex=7,xlab="Comp1 Mapped Score",ylab="Comp2 Mapped Score") 
legend("topleft", legend=c("Home","Away","Tie"),col=c(1,2,3), pch = ".",cex=1,text.width = 5,pt.cex = 7)

plot(emds[,1],emds[,2],main='2D Representation of MDS Results using Euclidean Distances\n for Unibet',cex.main = 1,xlab='', ylab='',col=results+1,pch=".",cex=7)
legend("bottomleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 5,pt.cex = 7)

plot(mmds[,1],mmds[,2],main='2D Representation of MDS Results using Manhattan Distances\n for Unibet',xlab='',cex.main = 1, ylab='',col=results+1,pch=".",cex=7)
legend("bottomleft", legend=c("Under 2.5","Over 2.5"),col=c(1,2), pch = ".",cex=1,text.width = 10,pt.cex = 7)

```

###Task 3
```{r appendix_prep2, eval=FALSE}
#Read the image
resim <- readJPEG("HW2_Resim.jpg")

#display the image
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(resim,0,0,1,1)
dim(resim)

par(mfrow=c(1,3))
resimr1 <- apply(resim[,,1], 2, rev)
resimr2 <- apply(resim[,,2], 2, rev)
resimr3 <- apply(resim[,,3], 2, rev)

#display each channel separately, take the reverse and the transpose in order to get the original picture with the image function
image(t(resimr1),ann=FALSE,axes=FALSE,col = grey(seq(0, 1, length = 256)))
image(t(resimr2),ann=FALSE,axes=FALSE,col = grey(seq(0, 1, length = 256)))
image(t(resimr3),ann=FALSE,axes=FALSE,col = grey(seq(0, 1, length = 256)))

m<-resim

#add uniform noise between [0,0.1] to every channel separately
m[,,1]<-resim[,,1] + matrix(runif(512*512,0,0.1),512,512)
m[,,2]<-resim[,,2] + matrix(runif(512*512,0,0.1),512,512)
m[,,3]<-resim[,,3] + matrix(runif(512*512,0,0.1),512,512)

#scale the values in order to display
m<-m/max(m)
#display the image with added noise
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(m,0,0,1,1)

#display each channel of the noisy image
#display each channel separately, take the reverse and the transpose in order to get the original picture with the image function
par(mfrow=c(1,3))
mr1 <- apply(m[,,1], 2, rev)
mr2 <- apply(m[,,2], 2, rev)
mr3 <- apply(m[,,3], 2, rev)

image(t(mr1),ann=FALSE,axes=FALSE,col = grey(seq(0, 1, length = 256)))
image(t(mr2),ann=FALSE,axes=FALSE,col = grey(seq(0, 1, length = 256)))
image(t(mr3),ann=FALSE,axes=FALSE,col = grey(seq(0, 1, length = 256)))

#take the average of the three channels to convert to grayscale
g<-m[,,1]+m[,,2]+m[,,3]
#normalize the values
g<-g/max(g)
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(g,0,0,1,1)

#determine the matrix of patches
count = 0
liste <-list(NULL)
for(i in c(1:510)){for(j in c(1:510)){
  vect<-c(((t(g[c(i:(i+2)),c(j:(j+2))]))))
  count = count + 1
  liste[[count]] = vect
}}

liste <-t(as.data.table(liste[]))

#reset the row indexes
#scale each channel intensities
#display each channel side by side
rownames(liste) <-NULL
pca<-princomp(liste)

#PC1
z<-pca$scores[,1]
z<-((z-min(z))/(max(z)-min(z)))
z<-t(matrix(z,510,510))

par(mfrow=c(1,3))
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(z,0,0,1,1)

#PC2
y<-pca$scores[,2]
y<-((y-min(y))/(max(y)-min(y)))
y<-t(matrix(y,510,510))

plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(y,0,0,1,1)

#PC3
x<-pca$scores[,3]
x<-((x-min(x))/(max(x)-min(x)))
x<-t(matrix(x,510,510))

plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(x,0,0,1,1)

#part c
#display the eigenvectors(loadings) matrix as an image
#do the scaling for every component

##this part is the PC1's eigenvalues' matrix without scaling with rasterImage function
l1<-matrix(pca$loadings[,1],3,3)
#l1 <- apply(l1, 2, rev)
#image((l1),xlab = 'Eigenvectors (without scaling) for Comp1',cex.lab = 3,axes=FALSE,col = grey(seq(0, 1, length #= 256)))
plot(0:1,0:1,type="n",axes=FALSE,ann=FALSE)
title(xlab='Eigenvectors (without scaling) for Comp1', line=0, cex.lab=1.2)
rasterImage(l1,0,0,1,1)
##

l1<-matrix(pca$loadings[,1],3,3)
l1<-((l1-min(l1))/(max(l1)-min(l1)))
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(l1,0,0,1,1)

l2<-matrix(pca$loadings[,2],3,3)
l2<-((l2-min(l2))/(max(l2)-min(l2)))
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(l2,0,0,1,1)

l3<-matrix(pca$loadings[,3],3,3)
l3<-((l3-min(l3))/(max(l3)-min(l3)))
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(l3,0,0,1,1)
```